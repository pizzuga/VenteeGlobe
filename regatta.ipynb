{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Import the whole Ventée Globe data in an Excel file**\n",
    "\n",
    "author: Stefano Romanelli\n",
    "\n",
    "email: romanelli@lamma.toscana.it\n",
    "\n",
    "date: 2021-02-20\n",
    "\n",
    "license for this ipynb: MIT\n",
    "\n",
    "license for the original data: ?\n",
    "\n",
    "\n",
    "## Purposes\n",
    "The following code permits to download xlsx files, containing information about the race, from https://www.vendeeglobe.org/ and merge all the data in a single big Excel file\n",
    "\n",
    "## Importing modules\n",
    "It's up to you to install them before!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path\n",
    "\n",
    "**Mandatory:** set the path of the directory of your hard drive where to save the Excel files. Unfortunately, for what I can understand, the original files are badly formatted, so it is impossible to create pandas dataframes that directly accesses the file in internet. We need to save them on the hard drive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.vendeeglobe.org/download-race-data/'\n",
    "\n",
    "# CHANGE IT!!! Use / not \\. Put / also at the end\n",
    "dir_path='C:/Users/romanel/Documents/regatta/files/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "### is_downlodable\n",
    "This funcion controls that the requested file is found on the web server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_downloadable(url, file_name):\n",
    "    \"\"\"\n",
    "    Does the url contain a downloadable resource\n",
    "    \"\"\"\n",
    "    h = requests.head(url + file_name, allow_redirects=True)\n",
    "    header = h.headers\n",
    "    content_type = header.get('content-type')\n",
    "    if 'text' in content_type.lower():\n",
    "        return False\n",
    "    if 'html' in content_type.lower():\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xl_read\n",
    "This function permits to create the \"global.xlsx\" file.\n",
    "Basically it saves the file on the HD (as said it is impossible to read the file directly on the server, at least I didn't succed), it creates a DataFrame of each file using columns \"B:U\" and skipping the firt 4 rows, adds the header (variable \"col\"), processes and adds 4 columns: 1) date 2) hour 3) latitude in DD 4) longitude in DD, and merge the actual file with the others previously processed\n",
    "\n",
    "As, during time, files change their formats (e.g. as soon as the first sailor finishes the race, it is added a new \"table\" in the sheet, or when sailors withdraw, they are still inserted in the dataframe each day), we filter out the rows in which the column Latitude is null (sailor has finished his/her race) or the column \"Rank\" is null (sailor withdrew). \n",
    "\n",
    "It is possible to change the path and the name of the global file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xl_read(file_list):    \n",
    "    \n",
    "    dfs = []\n",
    "\n",
    "    for f in file_list:\n",
    "        date = format(datetime.datetime.strptime(f[12:20], '%Y%m%d'),'%Y-%m-%d')\n",
    "        hour = format(datetime.datetime.strptime(f[21:27], '%H%M%S'),\"%H:%M:%S\")\n",
    "        col=[\"Rank\", \"Nation - Sail\", \"Skipper - crew\", \"Hour FR\", \"Latitude\", \"Longitude\", \"Heading - 30m.\", \"Speed - 30m.\", \"VMG- 30m.\", \"Distance - 30m.\", \"Heading - last rep.\", \"Speed - last rep.\", \"VMG- last rep.\", \"Distance - last rep.\", \"Heading - 24h\", \"Speed - 24h\", \"VMG- 24h\", \"Distance - 24h\", \"DTF\", \"DTL\"]\n",
    "        \n",
    "        r = requests.get(url + f, allow_redirects=True)\n",
    "        open(dir_path + f, 'wb').write(r.content)\n",
    "\n",
    "        df = pd.read_excel(\n",
    "                    dir_path + f,\n",
    "                    skipfooter=4,\n",
    "                    usecols=(\"B:U\"),\n",
    "                    skiprows=4,\n",
    "                    names=col\n",
    "                    )\n",
    "\n",
    "        df[\"date\"]=date\n",
    "        df[\"time\"]=hour\n",
    "\n",
    "        df = df[df['Latitude'].notna()]\n",
    "        df = df[df['Rank'].notna()]\n",
    "\n",
    "        df[\"lat\"]=df.apply(lambda row: \n",
    "             (int(row.Latitude[:row.Latitude.find('°')] ) + \n",
    "             int(row.Latitude[row.Latitude.find('°') + 1:row.Latitude.find('.')]) / 60 + \n",
    "             int(row.Latitude[row.Latitude.find('.') + 1:row.Latitude.find('\\'')]) / 3600) * \n",
    "             ns(row), axis=1)\n",
    "\n",
    "        df[\"long\"]=df.apply(lambda row: \n",
    "             (int(row.Longitude[:row.Longitude.find('°')] ) + \n",
    "             int(row.Longitude[row.Longitude.find('°') + 1:row.Longitude.find('.')]) / 60 + \n",
    "             int(row.Longitude[row.Longitude.find('.') + 1:row.Longitude.find('\\'')]) / 3600) * \n",
    "             ew(row), axis=1)\n",
    "\n",
    "        dfs.append(df)            \n",
    "    \n",
    "    return pd.concat(dfs).to_excel(dir_path + 'global.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ns & ew\n",
    "These functions are needed to convert correctly the coordinates from DMS to DD by assigning the minus sign where needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ns(row):\n",
    "    if row['Latitude'][-1:] == 'N':\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def ew(row):\n",
    "    if row['Longitude'][-1:] == 'E':\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing all the files!\n",
    "\n",
    "### file list \n",
    "This is the list where we store the name of all the Excel files to download and process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First day\n",
    "In the first day, the hours in the file name are different from the ones in the other days..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_frm='20201108'\n",
    "for i in ('140000', '150000', '170000', '210000'):\n",
    "    file_name='vendeeglobe_'+date_frm+'_'+i+'.xlsx'\n",
    "    if is_downloadable(url, file_name):\n",
    "        file_list.append(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Following days\n",
    "\n",
    "The end_date variable can be changed, but be aware that putting today date can lead to error at the end of the processing vanishing all the process!!!\n",
    "\n",
    "**Relax, take a coffee or a beer or both ;) smoke a cigarette (don't!) and after some couple of minutes you'll have your global.xlsx file create!**\n",
    "\n",
    "At the end of this block the xl_read(file_list) call the function to process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.date(2020, 11, 9)\n",
    "delta = datetime.timedelta(days=1)\n",
    "end_date = datetime.date(2021, 2, 20)\n",
    "\n",
    "while start_date <= end_date:\n",
    "    date_frm=start_date.strftime(\"%Y%m%d\")\n",
    "    for i in ('040000', '080000', '110000', '140000', '170000', '210000'):\n",
    "        file_name='vendeeglobe_'+date_frm+'_'+i+'.xlsx'\n",
    "        if is_downloadable(url, file_name):\n",
    "            file_list.append(file_name)\n",
    "    start_date += delta\n",
    "    \n",
    "xl_read(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
